#!/usr/bin/env python

"""
   Copyright 2016 The Trustees of Princeton University

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
"""

import os
import sys
import errno 
import cStringIO
import traceback
import signal
import json
import time
import threading
import atexit
import socket
import random

import syndicate.util.gateway as gateway

# singleton crawl thread
crawl_thread = None

class CrawlThread( threading.Thread ):

    def __init__(self, path, driver_mod):
        super(CrawlThread, self).__init__()
        self.running = False
        self.sock = None
        self.connection = None
        self.address = None
        self.path = path
        self.driver_mod = driver_mod


    @classmethod
    def bind_path( cls, path ):
        """
        Start serving on a UNIX domain socket.
        Return the socket on success
        """
        try:
            os.unlink(path)
        except:
            if os.path.exists(path):
                gateway.log_error("Failed to unlink '%s'" % path)
                return None

        try:
            sock = socket.socket( socket.AF_UNIX, socket.SOCK_STREAM )
            sock.bind( path )

            # only the AG should connect
            sock.listen(1)
            return sock

        except Exception, e:
            gateway.log_error("Failed to set up socket\n%s" % traceback.format_exc())
            return None


    @classmethod
    def crawl_rendezvous( cls, cmd_dict ):
        """
        Crawl implementation for the gateway module.
        Gets called by driver_mod.next_dataset()
        """
        global crawl_thread
        assert crawl_thread

        # feed back the dataset via the UNIX socket connection
        gateway.write_metadata_command( crawl_thread.connection, cmd_dict )
        rc = gateway.read_int( crawl_thread.connection )
        return rc
        

    @classmethod
    def crawl_stop( cls ):
        """
        Shut down the singleton thread.
        Use as an atexit callback
        """
        global crawl_thread
       
        try:
            crawl_thread.running = False

            try:
                crawl_thread.sock.close()
            except:
                pass

            crawl_thread.join()
            crawl_thread = None
        except Exception, e:
            gateway.log_error(traceback.format_exc())
            gateway.log_error("crawl_stop race")
            return
        

    def run(self):
        """
        Main thread
        """

        have_more = True
        finished = False
        
        self.running = True
        self.sock = CrawlThread.bind_path( self.path )

        if self.sock is None:
            gateway.log_error("Failed to bind to '%s', bailing" % self.path)
            return 

        next_dataset_tries = 0
        connect_tries = 0
        while self.running and have_more:
            # next dataset 
            try:
                # set up connection to AG
                gateway.log_error("Waiting for AG connection")
                connection, address = self.sock.accept()
                self.connection = connection
                self.address = address
                connect_tries = 0
            except:
                gateway.log_error("Caught global connection exception\n%s" % traceback.format_exc())
                connect_tries += 1
                delay = random.random() * (2**connect_tries) + 2**connect_tries
                gateway.log_error("Waiting %s seconds before trying again" % delay)
                time.sleep(delay)
                continue
            
            # serve up new dataset
            try:
                # NOTE: calls crawl_rendezvous() via gateway.crawl()
                have_more = driver_mod.next_dataset( driver_mod.CONFIG, driver_mod.SECRETS )
                next_dataset_tries = 0
            except Exception, e:
                gateway.log_error("next_dataset failed\n%s" % traceback.format_exc())
                
                gateway.log_error("Caught global 'next_dataset' exception\n%s" % traceback.format_exc())
                next_dataset_tries += 1
                delay = random.random() * (2**next_dataset_tries) + 2**next_dataset_tries
                gateway.log_error("Waiting %s seconds before trying again" % delay)
                time.sleep(delay)
                continue

            if not have_more:
                gateway.log_debug("No more datasets")
                if not finished:
                   # send back a "finished" stanza
                   gateway.log_debug("Finished crawling")
                   cmd = gateway.make_metadata_command( "finish", "directory", 0555, None, "/" )
                   CrawlThread.crawl_rendezvous( cmd )
                   finished = True

                # we're done here
                self.running = False
                self.sock.close()
            
            self.connection.close()
                
        return


if __name__ == "__main__":

    # it's okay if the driver doesn't have a 'serialize', 'deserialize', or 'refresh' method 
    default_callbacks = {
      'serialize': None,
      'deserialize': None,
      'refresh': None
    }

    usage, driver_mod = gateway.driver_setup( ['read', 'crawl', 'crawl', 'serialize', 'deserialize'], \
                                             ['read', 'next_dataset', 'refresh', 'serialize', 'deserialize'],
                                             default_callbacks=default_callbacks )

    # ready to go!
    # tell the parent that we're ready 
    print "0"
    sys.stdout.flush()

    if usage == "read":
      
      while True:
        
         tries = 0
         try:
             # read the path and metadata from stdin, write the chunk size and chunk to stdout
             request = gateway.read_request( sys.stdin )
             if request is None:
                print >> sys.stderr, "No more requests"
                sys.exit(3)
             
             chunk_fd = cStringIO.StringIO()
             rc = 0

             print >> sys.stderr, "read %s" % gateway.request_to_storage_path(request)

             # get it 
             try:
                rc = driver_mod.read( request, chunk_fd, driver_mod.CONFIG, driver_mod.SECRETS )
             except Exception, e:
                print >> sys.stderr, "read failed"
                print >> sys.stderr, traceback.format_exc()
                sys.exit(4)
             
             chunk = chunk_fd.getvalue()
             
             # send back the data!
             print >> sys.stderr, "read status: %s" % rc
             gateway.write_int( sys.stdout, rc )

             if rc == 0:
                 print >> sys.stderr, "read %s bytes" % len(chunk)
                 gateway.write_chunk( sys.stdout, chunk )

             sys.stdout.flush()
             sys.stderr.flush()
             tries = 0
         except Exception, e:
             gateway.log_error("Caught global 'read' exception\n%s" % traceback.format_exc())
             tries += 1
             delay = random.random() * (2**tries) + 2**tries
             gateway.log_error("Waiting %s seconds before trying again" % delay)
             time.sleep(delay)
             continue

    elif usage == "crawl":

       # canonical path to the UNIX domain socket
       # must be formatted as "$IPC_ROOT/$PID.sock"
       ipc_root = gateway.get_ipc_root()
       unix_socket_path = os.path.join( ipc_root, "%s.sock" % os.getpid() )

       # start serving dataset commands in a separate thread 
       # save it globally, and configure the `gateway` package 
       # to use it
       crawl_thread = CrawlThread( unix_socket_path, driver_mod )
       gateway.set_crawl_rendezvous_func( CrawlThread.crawl_rendezvous )
       atexit.register( CrawlThread.crawl_stop )
       crawl_thread.start()

       # begin listening for refreshes via stdin/stdout
       tries = 0
       while True:
           try:
               request = gateway.read_request( sys.stdin )
               if request is None:
                  gateway.log_error("FATAL: no request")
                  sys.exit(3)

               gateway.log_debug("refresh '%s'" % request.path)
               try:
                  rc = driver_mod.refresh( request, driver_mod.CONFIG, driver_mod.SECRETS )
               except Exception, e:
                  gateway.log_error("refresh failed on '%s'" % request.path)
                  gateway.log_error(traceback.format_exc())
                  sys.exit(4) 

               gateway.log_debug("refresh status: %s" % rc)
               gateway.write_int( sys.stdout, rc )
               sys.stdout.flush()
               sys.stderr.flush()
               tries = 0
           
           except Exception, e:
               gateway.log_error("Caught global 'crawl' exception\n%s" % traceback.format_exc())
               tries += 1
               delay = random.random() * (2**tries) + 2**tries
               gateway.log_error("Waiting %s seconds before trying again" % delay)
               time.sleep(delay)
               continue


